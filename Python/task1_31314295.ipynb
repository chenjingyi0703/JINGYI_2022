{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTOgTy-0zMsA"
   },
   "source": [
    "# Assessment 1 Parsing Data And Text Preprocessing\n",
    "## Task 1: Parsing Text Files\n",
    "*   Name: Jingyi Chen\n",
    "*   ID: 31314295"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRZck-lMzMek"
   },
   "source": [
    "### 1.0 Initializing the Environment\n",
    "> Load the google drive path to read the data source;\n",
    "\n",
    "> Import the packages needed for programming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3785,
     "status": "ok",
     "timestamp": 1649422905616,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "KyqnBrQwE6Pl",
    "outputId": "5a51beeb-8ff1-4947-fea6-a4039bd82e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1649422905616,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "xj0g2VyK28vr"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1649422905617,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "9j3jyQxbEEAt"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = \"\"\n",
    "directory = \"/content/drive/Shareddrives/FIT5196-s1-2022/A1/Task1/input_data/31314295/\"\n",
    "for file in os.listdir(directory):\n",
    "    f = open(directory + file, 'r')\n",
    "    data += f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o7ZWHVl-XTQ"
   },
   "source": [
    "### 2.0 Detected All The Tag Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AERTntKM3MxS"
   },
   "source": [
    "Call the re model of python and use the findall method to filter the data in the xml file. Use regular expressions to select all tag names, and then remove the duplicates to get all the tag name information.\n",
    "\n",
    "> Regular Expression: **\\\\$(.*?)\\\\.:**\n",
    "\n",
    "> Regular Expression Description: Due to we want to match the data in '<>' tags like users, reviews, summary and others. Like '$tags.:' this kind of data. So we use Regular Expression: **\\\\$(.*?)\\\\.:**. To prevent special characters from being transferred, we use backslashes to distinguish between these characters(\\$ and \\.). And (.*?) these characters is to match any character. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1649422906295,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "kFJBkPl8EQv8",
    "outputId": "4e717aea-86d1-4d85-9a4f-f248f00f1c35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 in 1913, now costs more than $50.Prior to 1913, if the government needed additional money, it could simply print the money itself. Abraham Lincoln did this during the Civil War when \"Greenbacks\" were issued. These were simply promissory notes like today\\'s Federal Reserve Notes that we think of as money. If you look at the top of any bill, you will see the words Federal Reserve Note. However, after the passage of the Federal Reserve Act, the government must now have a third party, the Fed, print the additional money it needs. This might not be such a horrible thing except for the fact that the government must now pay interest on this newly created money that it has borrowed from the Fed. In addition, this new money is the product of purchasing power that has been stolen from the people of the United States. So, in effect, the taxpayers must now pay interest on money that the Fed has stolen from them, and then loaned back to them.But wait. It gets worse.After the government borrows a trillion dollars from the Fed, it writes checks and spends the money. The military gets paid, people receive their Social Security checks, and so forth. After people receive these checks from the government, they deposit them into their bank accounts. Let\\'s say that someone receives a check for $1,000 from the government and deposits it into a savings account. Most people think that the bank will now have $1,000 (minus some percentage set aside for a reserve) that it can loan out. Wrong! Using the magic of something called Fractional Reserve Banking, the bank can loan out $9,000 for every $1,000 in deposits.Initially, the bank loans out $900 and holds $100 (10%) in reserve. However, the $900 that has been loaned out will ultimately be re-deposited into the banking system. When it is, the process will repeat itself with the bank loaning $810 and holding $90 (10%) in reserve. This process continues to repeat itself until the bank (i.e',\n",
       " '9,000 for every $1,000 that was originally deposited. At this point, the bank (i.e',\n",
       " 'Helpful?',\n",
       " 'No. helps',\n",
       " 'REVIEW',\n",
       " 'SUMMARY',\n",
       " 'prod_ID',\n",
       " 'product.ID',\n",
       " 'productID',\n",
       " 'rev_ID',\n",
       " 'rev_NAME',\n",
       " 'reviewDate',\n",
       " 'review_date',\n",
       " 'review_summary',\n",
       " 'review_text',\n",
       " 'reviewer.ID',\n",
       " 'reviewer.NAME',\n",
       " 'reviewerID',\n",
       " 'reviewerName'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the tag names by regular expression\n",
    "reg_name_tags = re.compile('\\$(.*?)\\.:')\n",
    "uni_tags = re.findall(reg_name_tags, data)\n",
    "uni_tags = set(uni_tags)\n",
    "uni_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGjJq_2p53oV"
   },
   "source": [
    "As the results show, there are many different tag names, except for the first sentence, which is an accidental match, three different cases for product ID, three different cases for review ID, and so on. When we need to rematch, we take all of these things into account so that we don't lose data.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGSvNmYV65S8"
   },
   "source": [
    "### 3.0 Defining Funtions and Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc-45ZgnAoqa"
   },
   "source": [
    "#### 3.1 Defining Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxjgVQbAlX6C"
   },
   "source": [
    "Define different regular expressions for different tags in order to extract data from those tags. Use the re.compile method to compile regular expressions for the following seven different tags, and then use it when extracting data.\n",
    "\n",
    "Regular expression syntax description:\n",
    ">  \\w+ Matches any alphanumeric character with many times\n",
    "\n",
    ">  \\d+ Matches any decimal digit with many times\n",
    "\n",
    ">  A | B means to match to the two cases can be A or B \n",
    "\n",
    "> Using backslashes to distinguish between these characters(\\$ and \\.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1649422906296,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "UVUIecdeESHV"
   },
   "outputs": [],
   "source": [
    "# define the regular expressions for different tags\n",
    "reg_rev_id = re.compile('\\$(rev_ID|reviewer.ID|reviewerID)\\.: (\\w+)')\n",
    "reg_prod_id = re.compile('\\$(prod_ID|product.ID|productID)\\.: (\\w+)')\n",
    "reg_rev_date = re.compile('\\$(reviewDate|review_date)\\.: (\\d+ \\d+, \\d+)')\n",
    "reg_rev_help = re.compile('\\$(Helpful\\?|No\\. helps)\\.: (\\[\\d+, \\d+\\])')\n",
    "reg_rev_text = re.compile('\\$(REVIEW|review_text)\\.: ')\n",
    "reg_rev_summ = re.compile('\\$(review_summary|SUMMARY)\\.: ')\n",
    "reg_rev_name = re.compile('\\$(rev_NAME|reviewer.NAME|reviewerName)\\.: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1649422906901,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "6rz-2jY5ETsN",
    "outputId": "87b93135-d4bd-4cda-c6fd-a92dc7366065"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('\\\\$(rev_NAME|reviewer.NAME|reviewerName)\\\\.: ') 40000\n",
      "re.compile('\\\\$(rev_ID|reviewer.ID|reviewerID)\\\\.: (\\\\w+)') 40000\n",
      "re.compile('\\\\$(prod_ID|product.ID|productID)\\\\.: (\\\\w+)') 40000\n",
      "re.compile('\\\\$(reviewDate|review_date)\\\\.: (\\\\d+ \\\\d+, \\\\d+)') 40000\n",
      "re.compile('\\\\$(Helpful\\\\?|No\\\\. helps)\\\\.: (\\\\[\\\\d+, \\\\d+\\\\])') 40000\n",
      "re.compile('\\\\$(REVIEW|review_text)\\\\.: ') 40000\n",
      "re.compile('\\\\$(review_summary|SUMMARY)\\\\.: ') 40000\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in different regular expressions\n",
    "for each in [reg_rev_name, reg_rev_id, reg_prod_id, reg_rev_date, reg_rev_help, reg_rev_text, reg_rev_summ]:\n",
    "    print(each, len(re.findall(each, data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QELP2aBHBQi6"
   },
   "source": [
    "These results show the number of rows of different regular expressions. All these regular expressions have 40000 rows. \n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59AYuZAvA7Cz"
   },
   "source": [
    "#### 3.2 Defining Funtions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54xIgMfpta7Q"
   },
   "source": [
    "Get data for different regular expressions: using the regular expression to split the data, and get the data from the tags\n",
    "\n",
    "> Date list type ('review_date', '03 28, 2013')\n",
    "\n",
    "> prod_id list type ('product.ID', 'B005DOK8NW')\n",
    "\n",
    "> helps list type ('Helpful? ', '[0, 0]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1649422906902,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "pvTZpSDzEauM"
   },
   "outputs": [],
   "source": [
    "def extract_data(data):\n",
    "    rev_dates = re.findall(reg_rev_date, data)[0][1]\n",
    "    prod_ids = re.findall(reg_prod_id, data)[0][1]\n",
    "    rev_helps = re.findall(reg_rev_help, data)[0][1]\n",
    "    \n",
    "    # Extract and split the data from tags\n",
    "    data_copy = data\n",
    "    data_copy = re.split(reg_rev_date, data_copy)\n",
    "    data_copy = [code for each in data_copy for code in re.split(reg_prod_id, each)]\n",
    "    data_copy = [code for each in data_copy for code in re.split(reg_rev_help, each)]\n",
    "    data_copy = [code for each in data_copy for code in re.split(reg_rev_id, each)]\n",
    "    data_copy = [code for each in data_copy for code in re.split(reg_rev_text, each)]\n",
    "    data_copy = [code for each in data_copy for code in re.split(reg_rev_summ, each)]\n",
    "    data_copy = [code for each in data_copy for code in re.split(reg_rev_name, each)]\n",
    "    \n",
    "    # Double-layer for loop retrieves review and summary data into an array\n",
    "    rev_txt_list = [data_copy[i+1] for i in range(len(data_copy))  if data_copy[i] in ['REVIEW', 'review_text']]\n",
    "    rev_summ_list = [data_copy[i+1] for i in range(len(data_copy))  if data_copy[i] in ['review_summary', 'SUMMARY']]\n",
    "        \n",
    "    return rev_dates, prod_ids, rev_helps, rev_txt_list[0], rev_summ_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiMAS2FF74Wa"
   },
   "source": [
    "_format_date function description:\n",
    "\n",
    "\n",
    "> Adding 0 in month and day for using in next part to compare the dates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1649422906902,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "7AQ0sXypEd4E"
   },
   "outputs": [],
   "source": [
    "def _format_date(date):\n",
    "    date_list = date.split()\n",
    "    # YEAR MONTH DAY\n",
    "    date_list = [date_list[-1], date_list[0], date_list[1]]\n",
    "\n",
    "    # Make sure all dates are in one format: 20220101\n",
    "    if len(date_list[-1]) < 3:\n",
    "      date_list = [date_list[0], date_list[1], '0' + date_list[-1]]\n",
    "    if len(date_list[1]) < 2:\n",
    "      date_list = [date_list[0], '0' + date_list[1], date_list[-1]]\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nflWfwL8Wu4"
   },
   "source": [
    "correct_content function description:\n",
    "\n",
    "> This method is used to replace special characters, null values, symbols, and NA values in data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1649422906902,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "08b5AJFEEho8"
   },
   "outputs": [],
   "source": [
    "## remove all the illegel characters\n",
    "def correct_content(context):\n",
    "    context = re.sub('&', '&amp;', context)\n",
    "    context = re.sub('\b', '', context)\n",
    "    re.sub('[\\\\x00-\\\\x08\\\\x0b-\\\\x0c\\\\x0e-\\\\x1f]','',context)\n",
    "    context = re.sub('&#27;', '', context)\n",
    "    context = re.split('\\n\\n\\n', context)\n",
    "    if context[-1] == \"\" or context[-1] == '\\n':\n",
    "        context = context[:-1]\n",
    "    context = '. '.join(context)\n",
    "    context = re.split('\\n', context)\n",
    "    context = [each for each in context if each != \"\"]\n",
    "    context = '. '.join(context)\n",
    "    context = re.sub(\"\\'\", '&#39;', context)\n",
    "    context = re.sub(\"^K\", ' ', context)\n",
    "    if context == 'nan':\n",
    "        context = 'NAN'    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-hoZeRwABDI"
   },
   "source": [
    "### 4.0 Extract The Data From Tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeTLuUh2BwZq"
   },
   "source": [
    "#### 4.1 Extract reviewer_id data From Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7i9SSJfBwe2"
   },
   "source": [
    "Use the review_id regular expression to **split** the match by calling the re.split method. Then data cleaning involves **removing null values and newlines**. Finally, through the for loop, all the values of a **Reviewer ID** were placed in a list, and all the values without a Reviewer ID were placed in a list. \n",
    "\n",
    "These two lists are used in next part. rev_ids list is used as the key to match the answer format. and the context list is used to extract the other data from tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1649422906903,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "p2vh-AARBis_",
    "outputId": "5007c7ac-b55e-4cf7-f597-363a7a76db7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A30YO2G0MDE1PG', 'A1TI7MZLZSEO4I', 'A2WVFAQUUWB94K', 'A5NNSSZRMVFMJ', 'A3KDP3BJ7GF5NT', 'A39DQIQ1GO2J4Y', 'AYNAH993VDECT', 'A12PZF121RG0HH', 'A3J6NW3S55DWLL', 'A3GCX2GDJ67ZWA']\n"
     ]
    }
   ],
   "source": [
    "data_copy = data\n",
    "data_copy = re.split(reg_rev_id, data_copy)\n",
    "data_copy = [each for each in data_copy if each not in ['\\n', \"\", ' ']] # remove the empty value and \\n value\n",
    "\n",
    "contexts = [data_copy[i] for i in range(2, len(data_copy), 3)] # except review_id\n",
    "all_rev_ids = [data_copy[i] for i in range(1, len(data_copy), 3)] # review id\n",
    "print(all_rev_ids[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJBEJdkhCmuO"
   },
   "source": [
    "#### 4.2 Extract All Data from Tags and Transfer to Json Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SnFyrhReDCQQ"
   },
   "source": [
    "Through the **for loop**, loop through the Reviewer ID and other fields. With reviewer ID as the key, other fields were nested in JSON and stored in the dictionary. If the Reviewer ID already exists and needs to compare dates, use the date conversion function **_format_date** to convert the dates, and then take the larger date as **latest_review_date**. Then add the JSON data for the Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 6976,
     "status": "ok",
     "timestamp": 1649422913874,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "3rKC6dWCEjNM"
   },
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i in range(len(all_rev_ids)):\n",
    "    rev_id = all_rev_ids[i]\n",
    "    cont = contexts[i]\n",
    "    date, prod_id, helps, review_text, summary = extract_data(cont)\n",
    "    if rev_id not in dic:\n",
    "        dic[rev_id] = \\\n",
    "        {\n",
    "            'latest_review_date':  date,\n",
    "            'reviews':[{\n",
    "                    'productID': prod_id,\n",
    "                    'review_date': date, \n",
    "                    'review_helpful': helps, \n",
    "                    'review_text':  correct_content(review_text),\n",
    "                    'review_summary':  correct_content(summary)\n",
    "                    }]\n",
    "        }\n",
    "    else:\n",
    "        new_dic = {\n",
    "                    'productID': prod_id,\n",
    "                    'review_date': date, \n",
    "                    'review_helpful': helps, \n",
    "                    'review_text':  correct_content(review_text),\n",
    "                    'review_summary':  correct_content(summary)\n",
    "                    }\n",
    "        old_date = _format_date(dic[rev_id]['latest_review_date'])\n",
    "        new_date = _format_date(date)\n",
    "        if new_date < old_date:\n",
    "            date = dic[rev_id]['latest_review_date']\n",
    "        \n",
    "        dic[rev_id] = \\\n",
    "        {\n",
    "            'latest_review_date': date,\n",
    "            'reviews': dic[rev_id]['reviews'] + [new_dic]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHbQP3xRJ6sp"
   },
   "source": [
    "### 5.0 Writing the Final Results to the File\n",
    "The code here is mainly used to convert the dictionary data into a file. Due to the specific format of assessment, we need to **concatenate some strings** such as **'<users>'**. Concatenate these strings with the data in the dictionary to get the final data, iterate through all the data through a **double-layer for loop**, and finally write it out to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 688,
     "status": "ok",
     "timestamp": 1649422914558,
     "user": {
      "displayName": "Jingyi Chen",
      "userId": "01575192393336659630"
     },
     "user_tz": -600
    },
    "id": "LKuv5ZLAEmdE"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/2020 August - Master of Data Science/31314295.xml', 'w') as d:\n",
    "    d.write('<users>' + '\\n')\n",
    "    for _id in dic:\n",
    "        date = dic[_id]['latest_review_date']\n",
    "        reviews = dic[_id]['reviews']\n",
    "        \n",
    "        d.write('<user name=\"' + _id + '\">' + '\\n')\n",
    "        d.write('<latest_review_date>' + date + '</latest_review_date>' + '\\n')\n",
    "        d.write('<reviews>' + '\\n')\n",
    "        for each in reviews:\n",
    "            prod_id = each['productID']\n",
    "            review_date = each['review_date']\n",
    "            review_helpful = each['review_helpful']\n",
    "            review_text = each['review_text']\n",
    "            review_summary = each['review_summary']\n",
    "            d.write('<review>' + '\\n')\n",
    "            \n",
    "            d.write('<productID>' + prod_id)\n",
    "            d.write('</productID>' + '\\n')\n",
    "            d.write('<review_date>' + review_date)\n",
    "            d.write('</review_date>' + '\\n')\n",
    "            d.write('<review_helpful>' + review_helpful)\n",
    "            d.write('</review_helpful>' + '\\n')\n",
    "            d.write('<review_text>' + review_text)\n",
    "            d.write('</review_text>' + '\\n')\n",
    "            d.write('<review_summary>' + review_summary)\n",
    "            d.write('</review_summary>' + '\\n')\n",
    "            d.write('</review>' + '\\n')\n",
    "        d.write('</reviews>' + '\\n')\n",
    "        d.write('</user>' + '\\n')\n",
    "    d.write('</users>')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "“week4copy_ipynb”的副本.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
